{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model.py - Embedding Model for Keyword Spotting\n",
        "\n",
        "Provides:\n",
        "- Embedding models that return vector embeddings for word images\n",
        "- Similarity functions (cosine similarity, euclidean distance)\n",
        "- Support for multiple backbones (SimpleCNN, ResNet18)\n",
        "\n",
        "Project: Keyword Spotting\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "#                           BACKBONE ARCHITECTURES\n",
        "# ============================================================================\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple CNN backbone for word image embedding.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim=128, dropout_rate=0.4):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Block 1: 1 -> 32 channels\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Block 2: 32 -> 64 channels\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Block 3: 64 -> 128 channels\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Block 4: 128 -> 256 channels\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Embedding layer\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(256, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network.\n",
        "        \"\"\"\n",
        "        # Block 1\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "\n",
        "        # Block 2\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "\n",
        "        # Block 3\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "\n",
        "        # Block 4\n",
        "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
        "\n",
        "        # Global pooling and embedding\n",
        "        x = self.global_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet18Backbone(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet18 backbone adapted for grayscale word images.\n",
        "\n",
        "    Uses pretrained ResNet18 with modified first conv layer for single-channel input.\n",
        "    Provides stronger feature extraction capabilities than SimpleCNN at the cost\n",
        "    of more parameters and slower inference.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim=128, pretrained=True):\n",
        "        super(ResNet18Backbone, self).__init__()\n",
        "\n",
        "        # Load pretrained ResNet18\n",
        "        weights = 'IMAGENET1K_V1' if pretrained else None\n",
        "        resnet = models.resnet18(weights=weights)\n",
        "\n",
        "        # Modify first conv layer for grayscale (1 channel instead of 3)\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Copy weights from pretrained (average across RGB channels)\n",
        "        if pretrained:\n",
        "            pretrained_weight = resnet.conv1.weight.data\n",
        "            self.conv1.weight.data = pretrained_weight.mean(dim=1, keepdim=True)\n",
        "\n",
        "        # Copy other layers from ResNet\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.layer4 = resnet.layer4\n",
        "        self.avgpool = resnet.avgpool\n",
        "\n",
        "        # Replace final FC layer\n",
        "        self.fc = nn.Linear(512, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through ResNet18 backbone.\"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "#                        MAIN EMBEDDING MODEL\n",
        "# ============================================================================\n",
        "\n",
        "class EmbeddingModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Main embedding model for keyword spotting.\n",
        "\n",
        "    This model takes word images as input and returns fixed-size embedding vectors.\n",
        "    The embeddings are designed such that similar words (same text content) have\n",
        "    similar embeddings in the vector space.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, backbone='simple_cnn', embedding_dim=128, pretrained=False):\n",
        "        super(EmbeddingModel, self).__init__()\n",
        "\n",
        "        self.backbone_name = backbone\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Select and initialize backbone\n",
        "        if backbone == 'simple_cnn':\n",
        "            self.backbone = SimpleCNN(embedding_dim=embedding_dim)\n",
        "        elif backbone == 'resnet18':\n",
        "            self.backbone = ResNet18Backbone(\n",
        "                embedding_dim=embedding_dim,\n",
        "                pretrained=pretrained\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Unknown backbone: '{backbone}'. \"\n",
        "                f\"Available options: 'simple_cnn', 'resnet18'\"\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Compute embedding for input word image(s).\n",
        "        \"\"\"\n",
        "        return self.backbone(x)\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        \"\"\"\n",
        "        Alias for forward pass. Returns embedding vector.\n",
        "\n",
        "        This method is provided for clarity and backward compatibility.\n",
        "        It has identical behavior to calling the model directly.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.forward(x)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "#                        SIMILARITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def cosine_similarity(embedding1, embedding2):\n",
        "    \"\"\"\n",
        "    Compute cosine similarity between two embeddings.\n",
        "\n",
        "    Cosine similarity measures the cosine of the angle between two vectors.\n",
        "    It is bounded in the range [-1, 1] where:\n",
        "        - 1.0: Vectors point in exactly the same direction (most similar)\n",
        "        - 0.0: Vectors are orthogonal (no similarity)\n",
        "        - -1.0: Vectors point in opposite directions (most dissimilar)\n",
        "    \"\"\"\n",
        "    return F.cosine_similarity(embedding1, embedding2, dim=-1)\n",
        "\n",
        "\n",
        "def euclidean_distance(embedding1, embedding2):\n",
        "    \"\"\"\n",
        "    Compute Euclidean (L2) distance between two embeddings.\n",
        "\n",
        "    The Euclidean distance is the straight-line distance between two points\n",
        "    in the embedding space. Lower values indicate more similar embeddings.\n",
        "\n",
        "    \"\"\"\n",
        "    return F.pairwise_distance(embedding1, embedding2, p=2)\n",
        "\n",
        "\n",
        "def similarity_matrix(embeddings):\n",
        "    \"\"\"\n",
        "    Compute pairwise cosine similarity matrix for a batch of embeddings.\n",
        "\n",
        "    This is useful for ranking and retrieval tasks where you need to compare\n",
        "    one query embedding against many candidate embeddings.\n",
        "    \"\"\"\n",
        "    # Normalize embeddings to unit vectors\n",
        "    embeddings_norm = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    # Compute pairwise cosine similarity as matrix multiplication\n",
        "    # (normalized vectors Â· normalized vectors^T)\n",
        "    similarity = torch.mm(embeddings_norm, embeddings_norm.t())\n",
        "\n",
        "    return similarity\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "#                        MODEL PERSISTENCE\n",
        "# ============================================================================\n",
        "\n",
        "def save_model(model, save_path, history=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Save model checkpoint to disk.\n",
        "\n",
        "    Saves the model state along with metadata including architecture parameters,\n",
        "    training history, and any custom information.\n",
        "    \"\"\"\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'backbone': model.backbone_name,\n",
        "        'embedding_dim': model.embedding_dim,\n",
        "        'history': history,\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, save_path)\n",
        "    print(f\" Model saved to {save_path}\")\n",
        "\n",
        "\n",
        "def load_model(checkpoint_path, device='cpu'):\n",
        "    \"\"\"\n",
        "    Load a trained model from checkpoint.\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Reconstruct model with saved architecture\n",
        "    model = EmbeddingModel(\n",
        "        backbone=checkpoint['backbone'],\n",
        "        embedding_dim=checkpoint['embedding_dim']\n",
        "    )\n",
        "\n",
        "    # Load trained weights\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Move to device and set to evaluation mode\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, checkpoint\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "#                        UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Count the number of trainable parameters in a model.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def get_model_info(model):\n",
        "    \"\"\"\n",
        "    Get detailed information about a model.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'backbone': model.backbone_name,\n",
        "        'embedding_dim': model.embedding_dim,\n",
        "        'num_parameters': count_parameters(model)\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "#                        TEST / DEMO CODE\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Test script to verify that all components work correctly.\n",
        "    Run this file directly to execute tests.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"MODEL.PY - Test Script\")\n",
        "    print(\"=\" * 70)\n",
        "    print()\n",
        "\n",
        "    # Test 1: SimpleCNN\n",
        "    print(\"Test 1: SimpleCNN Backbone\")\n",
        "    print(\"-\" * 70)\n",
        "    model_simple = EmbeddingModel(backbone='simple_cnn', embedding_dim=128)\n",
        "    print(f\" Model created\")\n",
        "    print(f\"  Parameters: {count_parameters(model_simple):,}\")\n",
        "\n",
        "    batch_size = 4\n",
        "    word_image = torch.randn(batch_size, 1, 64, 128)\n",
        "    print(f\" Input shape: {word_image.shape}\")\n",
        "\n",
        "    embedding = model_simple(word_image)\n",
        "    print(f\" Output shape: {embedding.shape}\")\n",
        "    print(f\" Embedding dimension: {embedding.shape[1]}\")\n",
        "    print()\n",
        "\n",
        "    # Test 2: ResNet18\n",
        "    print(\"Test 2: ResNet18 Backbone\")\n",
        "    print(\"-\" * 70)\n",
        "    model_resnet = EmbeddingModel(\n",
        "        backbone='resnet18',\n",
        "        embedding_dim=256,\n",
        "        pretrained=False\n",
        "    )\n",
        "    print(f\" Model created\")\n",
        "    print(f\"  Parameters: {count_parameters(model_resnet):,}\")\n",
        "\n",
        "    embedding = model_resnet(word_image)\n",
        "    print(f\" Output shape: {embedding.shape}\")\n",
        "    print()\n",
        "\n",
        "    # Test 3: Similarity functions\n",
        "    print(\"Test 3: Similarity Functions\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    emb1 = torch.randn(5, 128)\n",
        "    emb2 = torch.randn(5, 128)\n",
        "\n",
        "    cos_sim = cosine_similarity(emb1, emb2)\n",
        "    print(f\" Cosine similarity: {cos_sim}\")\n",
        "    print(f\"  Shape: {cos_sim.shape}\")\n",
        "    print(f\"  Range: [{cos_sim.min().item():.3f}, {cos_sim.max().item():.3f}]\")\n",
        "\n",
        "    euc_dist = euclidean_distance(emb1, emb2)\n",
        "    print(f\" Euclidean distance: {euc_dist}\")\n",
        "    print(f\"  Mean: {euc_dist.mean().item():.3f}\")\n",
        "\n",
        "    embeddings = torch.randn(10, 128)\n",
        "    sim_mat = similarity_matrix(embeddings)\n",
        "    print(f\" Similarity matrix shape: {sim_mat.shape}\")\n",
        "    print(f\"  Diagonal (self-similarity): {torch.diag(sim_mat)[:3]}\")\n",
        "    print()\n",
        "\n",
        "    # Test 4: Save and Load\n",
        "    print(\"Test 4: Save and Load\")\n",
        "    print(\"-\" * 70)\n",
        "    save_path = '/tmp/test_model.pth'\n",
        "\n",
        "    save_model(\n",
        "        model_simple,\n",
        "        save_path,\n",
        "        history={'train_loss': [0.5, 0.3, 0.2]},\n",
        "        test_metric=0.85\n",
        "    )\n",
        "\n",
        "    loaded_model, checkpoint = load_model(save_path)\n",
        "    print(f\" Model loaded\")\n",
        "    print(f\"  Backbone: {checkpoint['backbone']}\")\n",
        "    print(f\"  Embedding dim: {checkpoint['embedding_dim']}\")\n",
        "    print(f\"  Test metric: {checkpoint['test_metric']}\")\n",
        "    print()\n",
        "\n",
        "    test_output = loaded_model(word_image)\n",
        "    print(f\" Loaded model forward pass: {test_output.shape}\")\n",
        "    print()\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\" ALL TESTS PASSED!\")\n",
        "    print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGixro4Gj3oU",
        "outputId": "cffc6239-a1c7-400e-e567-cdcb23e64736"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MODEL.PY - Test Script\n",
            "======================================================================\n",
            "\n",
            "Test 1: SimpleCNN Backbone\n",
            "----------------------------------------------------------------------\n",
            " Model created\n",
            "  Parameters: 421,696\n",
            " Input shape: torch.Size([4, 1, 64, 128])\n",
            " Output shape: torch.Size([4, 128])\n",
            " Embedding dimension: 128\n",
            "\n",
            "Test 2: ResNet18 Backbone\n",
            "----------------------------------------------------------------------\n",
            " Model created\n",
            "  Parameters: 11,301,568\n",
            " Output shape: torch.Size([4, 256])\n",
            "\n",
            "Test 3: Similarity Functions\n",
            "----------------------------------------------------------------------\n",
            " Cosine similarity: tensor([-0.0103,  0.0977,  0.0332,  0.1420,  0.0650])\n",
            "  Shape: torch.Size([5])\n",
            "  Range: [-0.010, 0.142]\n",
            " Euclidean distance: tensor([15.3223, 14.8142, 15.0832, 14.4881, 15.9881])\n",
            "  Mean: 15.139\n",
            " Similarity matrix shape: torch.Size([10, 10])\n",
            "  Diagonal (self-similarity): tensor([1.0000, 1.0000, 1.0000])\n",
            "\n",
            "Test 4: Save and Load\n",
            "----------------------------------------------------------------------\n",
            " Model saved to /tmp/test_model.pth\n",
            " Model loaded\n",
            "  Backbone: simple_cnn\n",
            "  Embedding dim: 128\n",
            "  Test metric: 0.85\n",
            "\n",
            " Loaded model forward pass: torch.Size([4, 128])\n",
            "\n",
            "======================================================================\n",
            " ALL TESTS PASSED!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}